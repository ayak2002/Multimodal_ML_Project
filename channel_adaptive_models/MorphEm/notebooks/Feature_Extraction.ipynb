{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import skimage\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from timm import create_model\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import folded_dataset\n",
    "# reload(folded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871756c-b7b4-4d87-8b01-dafa58ac6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d6e77-1d8f-4d2c-af3e-b8522c81b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0827bf-b04e-483f-a5b3-aa3a8d852d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to add your own directory for data directory (i.e. root directory) and feature directory\n",
    "\n",
    "root_dir = '/scr/nnair/dataset/CHAMMI'\n",
    "feature_dir = '/scr/nnair/all_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb0a2f-a1ac-45db-ab38-493885fcdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_dataset(root_dir, dataset_name):\n",
    "    df_path = f'{root_dir}/{dataset_name}/enriched_meta.csv'\n",
    "    df = pd.read_csv(df_path)\n",
    "    dataset = folded_dataset.SingleCellDataset(csv_file=df_path, root_dir=root_dir, target_labels='train_test_split')\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74184c-95bd-4fcb-b73a-34735434bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_features(model, feature_dir, feature_file, root_dir, model_check):\n",
    "    dataset_names = ['CP','Allen','HPA']\n",
    "    for dataset_name in dataset_names:\n",
    "        dataset = configure_dataset(root_dir, dataset_name)\n",
    "        train_dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "        if model_check == \"resnet\":\n",
    "            preprocess = weights.transforms()\n",
    "        all_feat = []\n",
    "        for images, label in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "            cloned_images = images.clone()\n",
    "            batch_feat = []\n",
    "            for i in range(cloned_images.shape[1]):\n",
    "                # Copy each channel three times \n",
    "                channel = cloned_images[:, i, :, :]\n",
    "                channel = channel.unsqueeze(1)\n",
    "                expanded = channel.expand(-1, 3, -1, -1).to(device)\n",
    "        \n",
    "                if model_check == \"resnet\":\n",
    "                    expanded = preprocess(expanded).to(device)\n",
    "                    feat_temp = feature_extractor(expanded).cpu().detach().numpy()\n",
    "                else: \n",
    "                    feat_temp = forward(expanded).cpu().detach().numpy()\n",
    "                    \n",
    "                batch_feat.append(feat_temp)\n",
    "                \n",
    "            batch_feat = np.concatenate(batch_feat, axis=1)\n",
    "            all_feat.append(batch_feat)\n",
    "       \n",
    "        all_feat = np.concatenate(all_feat)\n",
    "        all_feat = all_feat.squeeze(2).squeeze(2)\n",
    "        feature_path = feature_path = f'{feature_dir}/{dataset_name}/{feature_file}'\n",
    "        np.save(feature_path, all_feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000e728-a0b5-4127-befb-1a3ce4321832",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convnext Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f90f0-84c6-40dd-9af8-8ee29e11ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm import create_model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9673ab7-c4b9-4727-ba1c-55df82b9e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x: torch.Tensor) -> torch.Tensor:\n",
    "    x = feature_extractor(x)\n",
    "    if pooling == 'avg':\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "    elif pooling == 'max':\n",
    "        x = F.adaptive_max_pool2d(x, (1, 1))\n",
    "    elif pooling == 'avg_max':\n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x = torch.cat([x_avg, x_max], dim=1)\n",
    "    elif pooling == None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Pooling {self.cfg.pooling} not supported. Use one of {FeaturePooling.list()}\"\n",
    "        )\n",
    "    # x = rearrange(x, \"b c h w -> b (c h w)\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff512b-d9db-421e-9057-93e241e222aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bced0f-5720-4cca-ba32-323a7e21d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file = 'pretrained_convnext_channel_replicate.npy'\n",
    "pooling = 'avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db255dc9-dee5-4ece-84b6-293ad7489e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "model = create_model(\"convnext_tiny.fb_in22k\", pretrained=pretrained).to(device)\n",
    "feature_extractor = nn.Sequential(\n",
    "                    model.stem,\n",
    "                    model.stages[0],\n",
    "                    model.stages[1],\n",
    "                    model.stages[2].downsample,\n",
    "                    *[model.stages[2].blocks[i] for i in range(9)],\n",
    "                    model.stages[3].downsample,\n",
    "                    *[model.stages[3].blocks[i] for i in range(3)],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938c58a-a0db-4c3a-99dc-e1d2bed61b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check = \"convnext\"\n",
    "get_save_features(model, feature_dir, feature_file, root_dir, model_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84e015",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ResNet Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d19fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file = 'pretrained_resnet18_features.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34397e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "m = resnet18(weights=weights).to(device)\n",
    "feature_extractor = torch.nn.Sequential(*list(m.children())[:-1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check = \"resnet\"\n",
    "get_save_features(m, feature_dir, feature_file, root_dir, model_check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
